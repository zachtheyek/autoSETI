{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "PQWEp6YP0w-C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "FjD6H04tiNVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Wrangling\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Data Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import ceil\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# ML\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Huggingface\n",
        "%pip install transformers\n",
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "# Miscellaneous\n",
        "from typing import List"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx9pa6uliPcn",
        "outputId": "2d36c881-2374-4837-f7e5-70f09d67effc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 443 kB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Hyperparameters"
      ],
      "metadata": {
        "id": "eJ7JDRxVLhsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epoch = 1"
      ],
      "metadata": {
        "id": "XVbLIzxDROWv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration\n",
        "\n",
        "Mount our Google Drive to this Colab instance, as if it were a local file system, and switch to the directory where the data are stored."
      ],
      "metadata": {
        "id": "KtIR_heEicC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive._mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/Research/Ongoing/Dynamic Spectra Sequence Modeling/Data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "eoCSYl22idiX",
        "outputId": "94c98602-af01-4c1f-e3cc-c10c150782ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2c48b20ae918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cd '/content/drive/MyDrive/Research/Ongoing/Dynamic Spectra Sequence Modeling/Data'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    290\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "pADy0Bm37gh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have five items of interest:\n",
        "\n",
        "\n",
        "* `train/` - a training set of cadence snippet files stored in `numpy` `float16` format (v1.20.1), one file per cadence snippet id, with corresponding labels found in the `train_labels.csv` file. Each file has dimension `(6, 273, 256)`, with the 1st dimension representing the 6 positions of the cadence, and the 2nd and 3rd dimensions representing the 2D spectrogram, i.e. frequency as a function of time.\n",
        "* `test/` - the test set cadence snippet files; our goal is to predict whether or not the cadence contains a \"needle\".\n",
        "* `train_labels.csv` - targets corresponding (by id) to the cadence snippet files found in the `train/` folder (1 if cadence contains a \"needle\", 0 if not).\n",
        "* `sample_submission.csv` - a sample submission file in the correct format.\n",
        "* `masked_labels.csv` - **[NOTE: I FORGOT WHAT THIS IS, ASK YUHONG]**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dq0H6_bTjqNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in both csv files into a `pd.DataFrame`, and check for any missing values."
      ],
      "metadata": {
        "id": "wwEGPs2_mCIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train_labels.csv')\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "Lsn9E8zviinj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "vJKgwNYEjKIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "5KF9UTHkjLfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('sample_submission.csv')\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "7XUvJIs1jNXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "id": "kIf_KppPja2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.info()"
      ],
      "metadata": {
        "id": "OwoqJ4t2jdN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Since there are no missing values to handle, collect the filepaths to each of the 60,000 train cadence snippets, and the 39,995 test cadence snippets, using `os.walk()`."
      ],
      "metadata": {
        "id": "0YIZ_HgRmPdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_filepaths, test_filepaths = [], []\n",
        "\n",
        "for root, dirs, files in os.walk('train'):\n",
        "  for filename in files:\n",
        "    train_filepaths.append(os.path.join(root, filename))\n",
        "\n",
        "for root, dirs, files in os.walk('test'):\n",
        "  for filename in files:\n",
        "    test_filepaths.append(os.path.join(root, filename))\n",
        "\n",
        "# Verify that we have the expected number of filepaths\n",
        "print(f'train: {len(train_filepaths)}\\ntest: {len(test_filepaths)}')"
      ],
      "metadata": {
        "id": "7hsFAmo6jeKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct a new `pd.DataFrame` with \"Filepath\" included alongside \"ID\" and \"Target\".\n"
      ],
      "metadata": {
        "id": "FqmWD60h39f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip the ID from each filepath\n",
        "train_id = [path[8:-4] for path in train_filepaths]\n",
        "test_id = [path[7:-4] for path in test_filepaths]\n",
        "\n",
        "# Look up target values from the previous DataFrame using ID values\n",
        "train_target = [df_train.loc[df_train['id'] == id]['target'].values[0] for _, id in tqdm(enumerate(train_id), total=60000)]\n",
        "test_target = [df_test.loc[df_test['id'] == id]['target'].values[0] for _, id in tqdm(enumerate(test_id), total=39995)]\n",
        "\n",
        "# Verify that we have the expected number of IDs and targets\n",
        "print(f'train: {len(train_id)}, {len(train_target)}\\ntest: {len(test_id)}, {len(test_target)}')"
      ],
      "metadata": {
        "id": "Jom3NBt94U8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame({'Filepath': train_filepaths,\n",
        "                         'ID': train_id,\n",
        "                         'Target': train_target})\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "aPJgqdyh6l-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.DataFrame({'Filepath': test_filepaths,\n",
        "                        'ID': test_id,\n",
        "                        'Target': test_target})\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "otoMzv6I_iVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, read in a single cadence snippet using `np.load()`, and check that its dimensions are indeed `(6, 273, 256)`."
      ],
      "metadata": {
        "id": "_UXNYTstsuvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndarray = np.load(df_train['Filepath'][0])\n",
        "ndarray.shape"
      ],
      "metadata": {
        "id": "P6QZGER_tA33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader\n",
        "\n",
        "Here we create a custom object with inheritance from PyTorch's `Dataset` class, to retrieve our data’s samples and corresponding labels, one at a time."
      ],
      "metadata": {
        "id": "nAVj06PZPcpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KaggleDataset(Dataset):\n",
        "  def __init__(self, \n",
        "               paths: List[str], \n",
        "               ids: List[str],\n",
        "               labels: List[int], \n",
        "               transform=None,\n",
        "               id_transform=None,\n",
        "               label_transform=None):\n",
        "    '''\n",
        "    The __init__ function is called when you instantiate the class.\n",
        "\n",
        "    Args:\n",
        "    - self: the instance of the class.\n",
        "    - paths: list of paths to the data, which are each cadence snippet files stored in np.float16 format, with dimensions (6, 273, 256).\n",
        "    - ids: list of snippet IDs to the cadence snippet files.\n",
        "    - labels: list of snippet labels to the cadence snippet files (1 if cadence contains a \"needle\", 0 if not).\n",
        "    - transform: optional transformation to be performed on a cadence snippet.\n",
        "    - id_transform: optional transformation to be performed on a snippet id.\n",
        "    - label_transform: optional transformation to be performed on a snippet label.\n",
        "    '''\n",
        "    self.paths = paths\n",
        "    self.ids = ids\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "    self.id_transform = id_transform\n",
        "    self.label_transform = label_transform\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    '''\n",
        "    The __len__ function returns the number of samples in our dataset.\n",
        "    '''\n",
        "    return len(self.ids)\n",
        "\n",
        "  def __getitem__(self, \n",
        "                  idx: int) -> (np.array, str, int):\n",
        "    '''\n",
        "    The __getitem__ function loads a cadence snippet from the dataset at the given index,\n",
        "    retrieves the corresponding id and label, calls the transform functions on them (if provided), \n",
        "    and returns all three values as a tuple.\n",
        "    '''\n",
        "    ndarray = np.load(self.paths[idx])\n",
        "    id = self.ids[idx]\n",
        "    label = self.labels[idx]\n",
        "    if self.transform:\n",
        "      ndarray = self.transform(ndarray)\n",
        "    if self.id_transform:\n",
        "      id = self.id_transform(id)\n",
        "    if self.label_transform:\n",
        "      label = self.label_transform(label)\n",
        "    return ndarray, id, label"
      ],
      "metadata": {
        "id": "vL-t129uAie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = KaggleDataset(paths=df_train['Filepath'].tolist(), \n",
        "                           ids=df_train['ID'].tolist(),\n",
        "                           labels=df_train['Target'].tolist())\n",
        "\n",
        "test_data = KaggleDataset(paths=df_test['Filepath'].tolist(), \n",
        "                          ids=df_test['ID'].tolist(),\n",
        "                          labels=df_test['Target'].tolist())"
      ],
      "metadata": {
        "id": "dngA63KLPgdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, we want to pass the cadence snippets in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s `multiprocessing` to speed up data retrieval. `DataLoader` is an iterable that abstracts this complexity for us in an easy API."
      ],
      "metadata": {
        "id": "wQzdOwQ7WGL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "74v2foJMRFUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've loaded the data into the `DataLoader` and can iterate through the dataset as needed, each iteration below returns a batch of `train_snippets`, `train_ids`, and `train_labels` (containing `batch_size=16` snippets, IDs, and labels, respectively). Note that because we specified `shuffle=True`, after we iterate over all batches, the data is shuffled."
      ],
      "metadata": {
        "id": "U5TUNx650sRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since torch.Tensor doesn't support strings, train_ids is returned as a tuple, which we'll immediately convert into an ndarray\n",
        "train_snippets, train_ids, train_labels = next(iter(train_dataloader))\n",
        "train_ids = np.asarray(train_ids)\n",
        "\n",
        "# Verify that the dimensions are in agreement with expectations\n",
        "print(f'Snippets batch shape: {train_snippets.shape}')\n",
        "print(f'IDs batch shape: {train_ids.shape}')\n",
        "print(f'Labels batch shape: {train_labels.shape}')"
      ],
      "metadata": {
        "id": "PvRATuqM0vng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try visualizing one of the cadence snippets."
      ],
      "metadata": {
        "id": "dAuVf8uCCvvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to plot samples (expected input: ndarray of shape [6, 273, 256])\n",
        "def plot_cadence_snippet(cad_snippet, title=None):\n",
        "    cad_snippet = cad_snippet.astype('float32')\n",
        "    num_obs, h, w = cad_snippet.shape\n",
        "    fig, axes = plt.subplots(6, 1, figsize=(10, 5))\n",
        "    axes = axes.flatten()\n",
        "    if title:\n",
        "        fig.suptitle(title)\n",
        "    for i in range(6):\n",
        "        axes[i].imshow(cad_snippet[i])\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_aspect(\"auto\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dmKh68S2Cyeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snippet, title = train_snippets[0].numpy(), f'ID: {train_ids[0]}, Target: {train_labels[0]}'\n",
        "plot_cadence_snippet(snippet, title)"
      ],
      "metadata": {
        "id": "3ZpPpnohC14_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "For preprocessing, we perform the following transformations:\n",
        "\n",
        "\n",
        "1.   Dimensionality reduction: since the BERT model only takes 2-dimensional inputs, we concatenate the cadence snippets pointing-wise, i.e. from `(6, 273, 256)` to `(1638, 256)`.\n",
        "2.   Downsampling: due to BERT's size limit of `512`, we downsample the time-axis by a factor of 4. **[NOTE: SINCE 1638 IS NOT DIVISIBLE BY 4, SWITCH TO USING LINEAR INTERPOLATION]**\n",
        "\n"
      ],
      "metadata": {
        "id": "d57HaRVWtMvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(snippets: torch.Tensor,\n",
        "                  batch_size: int) -> torch.Tensor:\n",
        "  '''\n",
        "  Preprocessing for the Kaggle dataset, which consists of dimensionality reduction + downsampling.\n",
        "\n",
        "  Args:\n",
        "  - snippets: a tensor of shape (batch_size, 1638, 256) that contains the cadence snippets.\n",
        "  - batch_size: the number of snippets we want to process at once.\n",
        "\n",
        "  Returns: \n",
        "  The preprocessed snippets.\n",
        "  '''\n",
        "  # Create a temporary tensor with the expected output size\n",
        "  tmp = torch.zeros(batch_size, 410, 256)\n",
        "  # Loop over each snippet and apply the appropriate preprocessing steps\n",
        "  for idx, snippet in enumerate(snippets):\n",
        "    snippet = snippet.reshape((1638, 256))\n",
        "    snippet = snippet[::4, :]\n",
        "    # Save the result to the temporary tensor\n",
        "    tmp[idx] = snippet\n",
        "  return tmp"
      ],
      "metadata": {
        "id": "xWKhnunqGNad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessing steps to the cadence snippets\n",
        "train_snippets = preprocessing(train_snippets, batch_size)\n",
        "# Verify that the resulting dimensions are consistent with expectations\n",
        "train_snippets.shape"
      ],
      "metadata": {
        "id": "caaRJky1FYJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Inference\n",
        "\n",
        "Using [HuggingFace](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel)'s pre-trained BERT model, we perform inference on the cadence snippets in batches."
      ],
      "metadata": {
        "id": "16_0rjtnyebA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a custom BERT configuration, where the number of attention heads must be a multiple of the hidden size\n",
        "configuration = BertConfig(hidden_size=256, num_attention_heads=16)\n",
        "\n",
        "# Initializing a model from the custom BERT configuration\n",
        "model = BertModel(configuration)\n",
        "\n",
        "# Forward pass of the model\n",
        "outputs = model.forward(inputs_embeds=train_snippets)\n",
        "\n",
        "# Collect the final classification tokens\n",
        "pooler_outputs = outputs.pooler_output\n",
        "\n",
        "# Verify that the resulting dimensions are as expected\n",
        "pooler_outputs.shape"
      ],
      "metadata": {
        "id": "MVkw7fr2yv6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All that's left is to feed in all of the available data into the model. With readibility in mind, we define a pipeline that includes preprocessing, inference, and postprocessing."
      ],
      "metadata": {
        "id": "cfMo1uzgUGPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(data, model, batch_size, outpath):\n",
        "  '''\n",
        "  A pipeline to perform inference on the Kaggle dataset, consisting of preprocessing, inference, and postprocessing.\n",
        "\n",
        "  Args:\n",
        "  - data: the dataset to be used, which includes filepaths to the cadence snippets, and their corresponding IDs and labels\n",
        "  - model: the model that will be used for inference\n",
        "  - batch_size: the number of samples to be processed in parallel\n",
        "  - outpath: the path to the directory where the outputs will be saved\n",
        "  '''\n",
        "  # Load the data into the DataLoader\n",
        "  loader = DataLoader(data, batch_size, shuffle=True)\n",
        "  # Wrap an iterator around the DataLoader\n",
        "  iterator = iter(loader)\n",
        "  # Disable gradient calculations to free up memory for inference\n",
        "  with torch.no_grad():\n",
        "    # Loop through the entire dataset, where if len(data) is not divisible by batch_size, the final iteration will have a reduced number of samples\n",
        "    for i in tqdm(range(ceil(len(data) / batch_size))):\n",
        "      # Read in the cadence snippets, as well as the corresponding IDs and labels\n",
        "      snippets, ids, labels = next(iterator)\n",
        "      # Perform preprocessing on the snippets\n",
        "      snippets = preprocessing(snippets, batch_size)\n",
        "      # Perform inference on the snippets from the forward pass of the model\n",
        "      outputs = model.forward(inputs_embeds=snippets)\n",
        "      # Collect the final classification tokens\n",
        "      pooler_outputs = outputs.pooler_output\n",
        "      # Save the outputs as .npy files in a separate directory\n",
        "      for idx, val in enumerate(pooler_outputs):\n",
        "        np.save(f'{outpath}{ids[idx]}_(1)', val.detach().numpy())"
      ],
      "metadata": {
        "id": "Tc2F9nKhQ6dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(data=train_data, \n",
        "         model=model, \n",
        "         batch_size=batch_size, \n",
        "         outpath='Results/')"
      ],
      "metadata": {
        "id": "g5ICd8ynVNME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n",
        "\n",
        "We perform t-SNE ([t-distributed Stochastic Neighbor Embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)) on the pooler outputs to visualize the model's latent space in 2-dimensions."
      ],
      "metadata": {
        "id": "ywbIJxAPdxkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load back in the data from our Results directory\n",
        "filepaths, id = [], []\n",
        "data = np.ndarray((60000, 256))\n",
        "\n",
        "for root, dirs, files in os.walk('Results'):\n",
        "  for filename in files:\n",
        "    filepaths.append(os.path.join(root, filename))\n",
        "for _, path in tqdm(enumerate(filepaths), total=60000):\n",
        "  np.append(data, np.load(path))\n",
        "  id.append(path[8:-8])\n",
        "\n",
        "# Create a separate list with aligning indices containing the labels to our data\n",
        "df = pd.read_csv('train_labels.csv')\n",
        "target = [df.loc[df['id'] == id]['target'].values[0] for _, id in tqdm(enumerate(id), total=60000)]\n",
        "\n",
        "# Verify that the dimensions of our data are correct\n",
        "data.shape"
      ],
      "metadata": {
        "id": "EXfghzvPf0Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the t-SNE embedding to our data\n",
        "tsne = TSNE(n_components=2)\n",
        "tsne_result = tsne.fit_transform(data)\n",
        "\n",
        "# Verify that the dimensions are correct\n",
        "tsne_result.shape"
      ],
      "metadata": {
        "id": "cgaCO-BDrDQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the result of our TSNE with the label color-coded, and \n",
        "tsne_result_df = pd.DataFrame({'tsne_1': tsne_result[:, 0], \n",
        "                               'tsne_2': tsne_result[:, 1], \n",
        "                               'label': target})\n",
        "fig, ax = plt.subplots(1)\n",
        "sns.scatterplot(x='tsne_1', y='tsne_2', hue='label', data=tsne_result_df, ax=ax, s=120)\n",
        "lim = (tsne_result.min() - 5, tsne_result.max() + 5)\n",
        "ax.set_xlim(lim)\n",
        "ax.set_ylim(lim)\n",
        "ax.set_aspect('equal')\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('Figures/BERT_(1).png')"
      ],
      "metadata": {
        "id": "_-rnOxrFhq63"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}